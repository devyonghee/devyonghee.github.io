---
title: '[Study] 운영체제 아주 쉬운 세가지 이야기 20장~24장'
tags: [study, book, operation-system]
categories: study
---

운영체제 아주 쉬운 세가지 이야기 책에 대한 스터디를 진행한다.  
이 글에서는 20장부터 24장까지의 내용을 정리한다. 

<!--more-->

## 20장. 페이징: 더 작은 테이블

페이징의 두번째 문제는 **페이지 테이블의 크기**다.  
페이지 테이블이 크면 많은 메모리 공간을 차지한다.  


### 20.1 간단한 해법: 더 큰 페이지

페이지 크기를 증가시키면 페이지 테이블의 크기를 줄일 수 있다.  
페이지 크기가 4배 증가되면 페이지 테이블의 크기는 1/4로 줄어든다.  

하지만 부작용으로 **내부 단편화(internal fragmentation)** 가 발생한다.  
페이지 내부의 낭비 공간이 증가하는 것이다.  
할당받은 페이지의 일부분만 사용하게 되기 때문에 메모리가 금방 고갈되는 현상이 발생된다.

### 20.2 하이브리드 접근 방법: 페이징과 세그멘트

페이징과 세그멘트 방법을 조합하는 것을 **하이브리드(hybrid)** 라고 한다.  
두 방법을 결합하여 테이블 크기를 줄이는 것이다.  

프로세스의 전체 주소 공간을 위한 페이지 테이블 대신, 논리 세그멘트마다 따로 페이지 테이블을 둔다.  
세그멘테이션은 물리 주속 시작 위치를 나타내는 **베이스(base)** 레지스터, 크기를 나타내는 **바운드(bound)** 또는 **리미트(limit)** 레지스터가 존재한다.  
여기서 베이스 레지스터는 세그먼트 시작 주소가 아니라 **세그멘트의 페이지 테이블의 시작 주소**를 갖는다.

TLB 미스가 발생한 경우 다음과 같이 동작한다. (하드웨어 기반으로 가정)

1. 하드웨어가 세그멘트 비트(SN) 을 사용하여 어떤 베이스와 바운드 쌍을 사용할지 결정
2. 레지스터에 있는 물리 주소를 VPN과 페이지 테이블 항목(PTE) 주소 획득

```text
SN           = (VirtualAddress & SEG_MASK) >> SN_SHIFT
VPN          = (VirtualAddress & VPN_MASK) >> VPN_SHIFT
AddressOfPTE = Base[SN] + (VPN * sizeof(PTE))
``` 

#### 문제점

- 세그멘테이션을 사용
  - 빈 공간이 많은 힙의 경우 페이지 테이블의 낭비를 면치 못함

- 외부 단편화 유발
  - 페이지 테이블 크기에 제한이 없어 다양한 크기를 가짐
  - 메모리상에서 테이블용 공간을 확보하는 것이 복잡


### 20.3 멀티 레벨 페이지 테이블


{% include image.html alt="선형(좌)과 멀티 레벨(우) 페이지 테이블" source_txt='운영체제 아주 쉬운 세가지 이야기' path="/images/study/operating-system/multi-level-page-table.png" %}

세그멘테이션을 사용하지 않고 페이지 테이블 크기를 줄이는 또 다른 방법은 **멀티 레벨 페이지 테이블(multi-level page table)** 이다.  
멀티 레벨 페이지 테이블에서는 선형 페이지 테이블을 트리 구조로 표현한다.  

멀티 레벨 페이지 테이블 개념은 다음과 같다. 

- 페이지 테이블을 페이지 크기의 단위로 나눈다.
- **페이지 디렉터리(page directory)** 자료 구조로 각 페이지의 할당 여부와 위치 파악
   - 페이지 디렉터리에는 페이지 테이블의 구성요소인 각 페이지의 존재 여부와 위치 정보를 가지고 있음
- 페이지 디렉터리는 **페이지 디렉터리 항목(page directory entries, PDE)** 들로 구성, 페이지 테이블의 한 페이지 표현 
  - PDE 의 구성은 PTE 와 유사, **유효 비트(valid)** 와 **페이지 프레임 번호(page frame number, PFN)** 를 가짐

{% include image.html alt="멀티 레벨 페이지 테이블 가상 주소 공간" source_txt='운영체제 아주 쉬운 세가지 이야기' path="/images/study/operating-system/multi-level-page-table-virtual-address-space.png" %}

- VPN 에서 페이지-디렉터리 인덱스(page-directory index, PDIndex) 추출하여 PDE 주소 찾음
  - `PDEAddr = PageDirBase + (PDIndex * sizeof(PDE))`
- PDE 가 유효하다면 VPN 나머지 주소로 **페이지-테이블 인덱스 (page-table index, PTIndex)**
  - `PTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))`
- `PhysAddr = (PTE.PFN << SHIFT) + offset`
- 2단계 이상인 경우 페이지 디렉터리가 추가되면서 가상 주소가 새로운 PD Index 로 추가 분할

#### 장점

- 사용된 주소 공간의 크기에 비례하여 페이지 테이블 공간 할당
  - 작은 크기의 페이지 테이블로 주소 공간 표현 가능
- 페이지 테이블을 페이지 크기로 분할하여 메모리 관리 용이
  - 페이지 테이블이 산재해 있어도 페이지 디렉터리로 위치 파악이 가능하므로 공간 할당이 유연

#### 문제점

- 추가 비용 발생
  - TLB 미스 시, 주소 변환을 위해 두 번의 메모리 로드 발생 (페이지 디렉터리 와 PTE 접근)
  - TLB 히트 시 성능은 동일, TLB 미스 시 두 배의 시간 소요
- 복잡도
  - 메모리 자원 절약을 위해, 페이지 테이블 검색이 복잡


### 20.4 역 페이지 테이블

또 다른 공간 절약 방법으로 **역 페이지 테이블(inverted page table)** 이 존재한다.    
여러 개의 페이지 테이블(프로세스당 하나씩) 대신 시스템에 단 하나의 페이지를 두는 것이다.  

- 물리 페이지를 가상 주소 상의 페이지로 변환
- 각 항목은 물리 페이지를 사용중인 **프로세스 번호**, 해당 **가상 페이지 번호** 를 가지고 있음
- 주소 변환을 위해 전체 테이블 검색
  - 탐색 속도 향상을 위해 주로 해시 테이블 사용

### 20.5 페이지 테이블을 디스크로 스와핑하기

모든 페이지 테이블을 메모리에 상주하기에는 너무 크다.  
어떤 시스템들은 페이지 테이블들을 커널 가상 메모리에 위치시키고, 메모리가 부족하면 디스크에 **스왑(swap)** 한다. 

<br/>

## 21장. 물리 메모리 크기의 극복: 메커니즘

다수의 프로세스들이 동시에 큰 주소 공간을 사용하는 상황을 가정한다.  
이를 위해 메모리 계층에 레이어 추가가 필요하다.  
현대 시스템에서는 보통 **하드 디스크 드라이브**를 큰 주소 공간을 보관해두는 공간으로 사용된다.   

편리함과 사용 용이성을 위해 프로세스에게 주소 공간을 충분히 제공해야 한다.  
**스왑 공간** 을 사용하면 프로세스들에게 큰 가상 메모리가 있는 것 같은 환상을 줄 수 있다.  

### 21.1 스왑 공간

**스왑 공간(swap space)** 은 디스크에 페이지들을 저장할 수 있는 일정 공간이다.  

- 스왑 공간의 입출력 단위는 페이지라고 가정
  - swap out: 메모리 페이지를 읽어서 스왑 공간에 저장
  - swap in: 페이지를 읽어 메모리에 탑재
- 운영체제는 스왑 공간에 있는 모든 페이지들의 **디스크 주소** 를 저장해야 함  
- 스왑 공간을 이용하면, 실제 물리메모리 공간보다 많은 공간이 존재하는 것처럼 가장 가능
- 스왑 공간에만 스왑을 할 수 있는 것은 아님
  - 코드 영역의 물리 페이지는 다른 페이지가 사용할 수 있는데 이는 파일 시스템 영역을 스왑 목적으로 사용하는 것임  


### 21.2 Present Bit

하드웨어 기반 TLB 를 사용하는 시스템에서 메모리 참조 과정을 다시 살펴본다.  

#### TLB 히트

1. 가상 주소에서 VPN 추출
2. TLB 에 정보가 있는지 검사(TLB 히트)
3. 물리 주소 얻은 후 메모리로 가져옴

#### TLB 미스

1. 가상 주소에서 VPN 추출
2. TLB 에 정보가 있는지 검사(TLB 미스)
3. 페이지 테이블의 메모리 주소 파악(페이지 테이블 베이스 레지스터 이용)
4. VPN 을 인덱스로 **페이지 테이블 항목(PTE)** 추출
5. 물리메모리에 존재하면 PTE 에서 PFN 정보 추출 후 TLB 탑재
6. 명령어 재실행

페이지가 디스크로 스왑되기 위해서 **present bit** 를 이용하여 PTE 에서 페이지가 물리 메모리에 존재하는지 여부를 표시한다.  
1 이라면 물리 메모리에 페이지 존재, 0이면 디스크 어딘가에 존재하는 것이다.  

물리 메모리에 존재하지 않는 페이지를 접근하는 행위는 **페이지 폴트(page fault)** 라고 한다.
페이지 폴트가 발생하면 운영체제로 제어권이 넘어가며 **페이지 폴트 핸들러(page-fault handler)** 가 실행된다.


### 21.3 페이지 폴트

페이지 폴트가 발생하면 운영체제의 **페이지 폴트 핸들러** 가 처리한다.  
페이지 폴트 발생 시, 운영체제는 페이지 테이블 항목(PTE) 에서 페이지의 디스크상 위치를 파악하여, 메모리로 탑재한다.  

1. 디스크 I/O 가 완료되면 운영체제는 PTE 의 PFN 값을 탑재된 페이지의 메모리 위치로 갱신
2. 페이지 폴트를 발생시킨 명령어 재실행
3. 재실행으로 인해 TLB 미스가 발생되면 TLB 미스 처리 과정이후 TLB 값 갱신(페이지 폴트 처리시 함께 갱신도 가능)
4. 재실행 시에 TLB 에서 주소 변환 정보 찾고 물리 주소에서 데이터 가져옴

I/O 실행은 시간이 많이 소요되므로 프로세스는 **차단된(blocked)** 상태가 된다.    
멀티 프로그램된 시스템에서는 다른 프로세스의 실행을 **중첩(overlap)** 시킬 수 있다.  

### 21.4 메모리에 빈 공간이 없으면?

스왑 공간으로부터 **페이지를 가져오기 위한 (page-in)** 여유 메모리가 부족하면, 다른 페이지들을 먼저 **페이지 아웃(page-out)** 할 수 있다.  
**교체(replace)** 페이지를 선택하는 것이 **페이지 교체 정책(page-replacement policy)** 라고 한다.  


### 21.5 페이지 폴트의 처리 

1. 탑재할 페이지를 위한 물리 프레임 확보
2. 여유 프레임이 없으면 교체 알고리즘으로 페이지 아웃(page-out) 으로 여유 공간 확보
3. I/O 요청ㅇ로 스왑 영역에서 페이지 읽어옴
4. 페이지 테이블을 갱신하고 명령어 재실행
5. 재실행하면 TLB 미스가 발생하며, 다시 재시도할 때 TLB 히트


### 21.6 교체는 실제 언제 일어나는가

교체 알고리즘은 효율적이지 않기 때문에 운영체제는 항상 여유 메모리 공간을 확보하고 있어야 한다.  
그래서 대부분의 운영체제들은 여유 공간에 관련된 **최댓값(high watermark, HW)** 과 **최솟값(low watermark, LW)** 을 설정하여 교체 알고리즘 작동에 활용한다.  
여유 공간의 크기가 **최솟값보다 작아지면** 여유 공간 확보를 위한 백그라운드 쓰레드가 **최댓값에 이를 때까지** 페이지를 제거한다.
백그라운드 쓰레드는 **스왑 데몬(swap daemon)** 또는 **페이지 데몬(page daemon)** 이라고 불린다.  

많은 시스템들은 성능을 높이기 위해 페이지들을 **클러스터(cluster)** 나 **그룹(group)** 으로 묶어 스왑 파티션에 저장하여 디스크의 효율을 높인다.  

<br/>

## 22장. 물리 메모리 크기의 극복: 정책

운영체제는 빈 메모리 공간이 부족해서 **메모리 압박(memory pressure)** 을 받으면 강제적으로 **페이징 아웃(paging out)** 을 수행한다.  
내보낼(evict) 페이지 선택은 페이지 교체 정책에 의해 결정된다.  

### 22.1 캐시 관리

캐시를 위한 교체 정책의 목표는 캐시 미스를 최소화, 캐시 히트를 최대화하는 것이다.  
캐시 히트와 미스 횟수를 알면 **평균 메모리 접근 시간(average memory access time, AMAT)** 을 계산할 수 있다.  

AMAT = T<sub>M</sub> + (P<sub>Miss</sub> * T<sub>D</sub>)

- T<sub>M</sub> : 메모리 접근 비용
- T<sub>D</sub> : 디스크 접근 비용
- P<sub>Miss</sub> : 캐시 미스 확률


### 22.2 최적 교체 정책

교체 정책을 이해하기 위해서는 **최적 교체 정책(The Optimal Replacement Policy)** 을 아는 것이 좋다.  
최적 교체 정책은 가장 나중에 접근될 페이지를 교체하여 미스를 최소화 한다.

{% include image.html alt="최적의 교체 정책의 흐름" source_txt='운영체제 아주 쉬운 세가지 이야기' path="/images/study/operating-system/optimal-replacement-policy.png" %}

캐시가 비워진 상태이기 때문에 첫 세 번은 미스가 발생된다.  
이러한 미스는 **최초 시작 미스(cold start miss)** 또는 **강제 미스(compulsory miss)** 라고 한다.   
그리고 현재 탑재되어 있는 페이지들 미래를 살펴보고 먼 미래에 접근될 페이지를 내보낸다.  
하지만 일반적으로 미래는 알 수 없기 때문에 최적 기법의 **구현은 불가능** 하다.  

### 22.3 간단한 정책: FIFO 

{% include image.html alt="FIFO 정책의 흐름" source_txt='운영체제 아주 쉬운 세가지 이야기' path="/images/study/operating-system/page-fifo-policy.png" %}

FIFO 교체 방식에서 페이지가 시스템에 들어오면 큐에 삽입되고, 교체를 해야할 경우 큐의 테일에 있는 페이지가 내보내진다.  
FIFO 교체 방식은 구현이 쉽지만 성능이 안좋다.  

### 22.4 또 다른 간단한 정책: 무작위 선택

이 방식은 무작위로 선택하여 교체하는 방식이다.  
구현은 쉽지만 내보낼 페이지가 제대로 선택되지 않을 수 있다.  
무작위 선택 방식의 성능은 그때그때 달라진다.  

### 22.5 과거 정보의 사용: LRU

페이지 교체 정책이 활용될 수 있는 페이지의 정보는 **빈도수(frequency)** 와 **최근성(recency)** 가 있다.  
**지역성의 원칙(principle of locality)** 에 따르면 최근에 접근된 페이지일수록 다시 접근될 확률이 높다.  
그래서 과거 이력을 기반한 다음과 같은 교체 알고리즘들이 존재한다. 

- Least-Frequently-Used(LFU) : 가장 적은 빈도로 사용된 페이지 교체
- Least-Recently-Used(LRU) : 가장 오래 전에 사용됐던 페이지 교체

이와 반대인 정책도 존재하지만 지역성 접근 특성을 무시하기 때문에 잘 동작하지 않는다.

- Most-Frequently-Used(MFU) : 가장 많은 빈도로 사용된 페이지 교체
- Most-Recently-Used(MRU) : 가장 최근에 사용된 페이지 교체

### 22.6 워크로드에 따른 성능 비교

- 지역성이 없다면 어느 정책을 사용하든 상관 없음
  - LRU, FIFO, 무작용 선택 모두 비슷한 성능을 보임
- 캐시가 충분히 커서 모든 워크로드를 포함할 수 있다면 어느 정책을 사용하든 상관 없음
  - 모든 블럭들이 캐시에 들어갈 수 있으면 히트율이 100%
- 최적 기법이 다른 정책들보다 좋은 성능을 보임

- 80대 20 워크로드 인 경우 (20% 페이지들에서 80% 참조, 80% 페이지들에서 20% 참조)
  - 최적 기법 > LRU > FIFO 순서로 좋은 성능을 보임

- 순차 반복 워크로드인 경우 (여러 페이지들을 순차적으로 참조)
  - 오래된 페이지들을 내보내기 때문에 LRU 와 FIFO 정책에서 가장 안좋은 성능을 보임
  - 무작위 선택 정책은 최적 기법보다 미치지는 못하지만 좋은 성능

### 22.7 과거 이력 기반 알고리즘 구현

과거 정보에 기반은 둔 정책을 구현하기 위해서는 많은 작업이 필요하다.  
어떤 페이지가 가장 최근 또는 오래 전에 사용됐는지 참조 정보 기록이 필요하지만, 기록에 주의하지 않으면 성능이 떨어질 수 있다.  

시스템 페이지 수가 증가하면 가장 오래전에 사용된 페이지를 찾는데 고비용 연산이 된다.  
가장 오래된 페이지가 아닌 비슷하게 오래된 페이지를 찾는 방법을 고민해본다.  

### 22.8 LRU 정책 근사하기 

LRU 를 근사하는 식으로 만들면 구현이 쉬워진다.  
이를 위해 **use bit(또는 reference bit)** 가 필요하다.  
각 페이지 마다 하나의 use bit 가 있으며 페이지가 참조될 때마다 1로 설정된다.  

use bit 를 활용하는 방법들에 대해 알아본다. 

- **시계 알고리즘(clock algorithm)**
  1. 모든 페이지들이 환형 리스트로 구성한다고 가정
  2. 시계 바늘 (clock hand) 이 특정 페이지를 가리킴
  3. 페이지를 교체해야할 때 현재 바늘이 가리키는 페이지의 use bit 검사
  4. 1이라면 최근에 사용된 것이므로 교체 대상이 아니면서 use bit 를 0으로 설정
  5. 시계 바늘은 P+1 로 이동
  6. 0으로 설정된 페이지를 찾을 때까지 반복

- **Corbato** 알고리즘
  - 미사용 페이지를 찾기 위해 모든 메모리를 검사하지 않아도 되는 특성을 지님

- 변형된 시계 알고리즘
  - 교체할 때 페이지들을 랜덤하게 검사

- **탐색 내성(scan resistance)**
  - 대개 LRU와 동작은 유사하지만 최악의 경우에 보이는 행동을 방지

### 22.9 갱신된 페이지(Dirty Page)의 고려

페이지가 **변경(modified)** 되어 **더티(dirty)** 상태가 되었다면,  
디스크에 기록해야하기 때문에 비용이 많이 든다.  
이러한 이유로 페이지를 내보낼 때 더티 페이지보다 **깨끗한 페이지** 를 교체하는 것을 선호한다.  

변경 여부를 판단하기 위해 하드웨어는 **modified bit(더티 비트)** 를 포함한다.  
페이지가 변경되면 이 비트가 1로 설정되는데 이를 고려하여 교체 대상이 선택된다.  

### 22.10 다른 VM 정책들

페이지 교체 정책만이 유일한 정책이 아니다.  

- **페이지 선택(page selection)** 정책
  - 언제 페이지를 메모리로 불러들일지 결정

- **요구 페이징(demand paging)** 정책
  - 페이지가 실제 접근될 때 해당 페이지를 메모리로 읽어 들임
  - 어떤 페이지가 사용될지 예상하여 미리 읽어 들일 수도 있음 (**선반입(prefetching)**)

- **클러스터링(clustering)** 또는 **쓰기 모으기(grouping or write)**
  - 기록해야 할 페이지들을 메모리에 모은 후 한번에 기록하는 방식
  - 디스크 드라이브는 여러 개 작은 크기보다 하나의 큰 쓰기 요청이 더 효율적임

### 22.11 쓰레싱(Thrashing)

실행 중인 프로세스가 가용 물리 메모리 크기를 초과하면 시스템은 끊임없이 페이징을 한다.  
이러한 상황을 **쓰래싱(thrashing)** 이라고 한다.  

운영체제들에는 쓰래싱이 발생했을 때 발견과 해결을 위한 기법들이 존재한다.  

- 일부 프로세스를 중지하여 나머지 프로세스를 탑재 
  - 프로세스가 일정 시간동안 사용하는 페이지들의 집합을 **워킹 셋(working set)** 이라고 하며, **진입 제어(admission control)** 방법을 활용
  - 많은 일을 엉성하게 하는 것보다 적은 일을 제대로 하는 것이 나음

- **메모리 부족 킬러(out-of-memory killer)** 실행  
  - 많은 메모리를 요구하는 프로세스를 골라 죽임

